{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications, backend, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "hx = hy = 150\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, hx, hy)\n",
    "else:\n",
    "    input_shape = (hx, hy, 3)\n",
    "\n",
    "# path to the model weights files trained with bottle-neck\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train_small'\n",
    "validation_data_dir = 'data/val_small'\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 200\n",
    "epochs = 50\n",
    "batch_size = 25\n",
    "\n",
    "# build the VGG16 network into model\n",
    "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# define top model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# load pre-trained top model weights\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add top model on top of vgg model\n",
    "# model.add(top_model)\n",
    "model = Model(inputs=model.input, outputs=top_model(model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# Keep very slow learning rate to avoid deterioriation of learned parameters\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., validation_steps=200, epochs=50, steps_per_epoch=80)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 [==============================] - 1783s 22s/step - loss: 0.6765 - acc: 0.9305 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 1646s 21s/step - loss: 0.6531 - acc: 0.9320 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 1491s 19s/step - loss: 0.5989 - acc: 0.9350 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 1430s 18s/step - loss: 0.6503 - acc: 0.9255 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 1416s 18s/step - loss: 0.6489 - acc: 0.9295 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 1408s 18s/step - loss: 0.6868 - acc: 0.9290 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 7/50\n",
      "80/80 [==============================] - 1395s 17s/step - loss: 0.6165 - acc: 0.9350 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 8/50\n",
      "80/80 [==============================] - 1396s 17s/step - loss: 0.6289 - acc: 0.9270 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 9/50\n",
      "80/80 [==============================] - 1403s 18s/step - loss: 0.6324 - acc: 0.9345 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 10/50\n",
      "80/80 [==============================] - 1401s 18s/step - loss: 0.6687 - acc: 0.9230 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 11/50\n",
      "80/80 [==============================] - 1395s 17s/step - loss: 0.6207 - acc: 0.9305 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 12/50\n",
      "80/80 [==============================] - 1387s 17s/step - loss: 0.4411 - acc: 0.9405 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 13/50\n",
      "80/80 [==============================] - 1392s 17s/step - loss: 0.7040 - acc: 0.9245 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 14/50\n",
      "80/80 [==============================] - 1393s 17s/step - loss: 0.6908 - acc: 0.9285 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 15/50\n",
      "80/80 [==============================] - 1401s 18s/step - loss: 0.6573 - acc: 0.9315 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 16/50\n",
      "80/80 [==============================] - 1395s 17s/step - loss: 0.6591 - acc: 0.9235 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 17/50\n",
      "80/80 [==============================] - 1401s 18s/step - loss: 0.6540 - acc: 0.9305 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "80/80 [==============================] - 1401s 18s/step - loss: 0.6222 - acc: 0.9350 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 19/50\n",
      "80/80 [==============================] - 1393s 17s/step - loss: 0.6945 - acc: 0.9240 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 20/50\n",
      "80/80 [==============================] - 1401s 18s/step - loss: 0.7433 - acc: 0.9260 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 21/50\n",
      "80/80 [==============================] - 1399s 17s/step - loss: 0.6381 - acc: 0.9285 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 22/50\n",
      "80/80 [==============================] - 1396s 17s/step - loss: 0.6532 - acc: 0.9320 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 23/50\n",
      "80/80 [==============================] - 1398s 17s/step - loss: 0.6510 - acc: 0.9330 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 24/50\n",
      "80/80 [==============================] - 1394s 17s/step - loss: 0.6698 - acc: 0.9215 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 25/50\n",
      "80/80 [==============================] - 1395s 17s/step - loss: 0.6499 - acc: 0.9295 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 26/50\n",
      "80/80 [==============================] - 1396s 17s/step - loss: 0.6314 - acc: 0.9310 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "80/80 [==============================] - 1393s 17s/step - loss: 0.6873 - acc: 0.9230 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 28/50\n",
      "80/80 [==============================] - 1392s 17s/step - loss: 0.5519 - acc: 0.9340 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 29/50\n",
      "80/80 [==============================] - 1394s 17s/step - loss: 0.6536 - acc: 0.9285 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 30/50\n",
      "80/80 [==============================] - 1391s 17s/step - loss: 0.6825 - acc: 0.9300 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 31/50\n",
      "80/80 [==============================] - 1391s 17s/step - loss: 0.6582 - acc: 0.9285 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 32/50\n",
      "80/80 [==============================] - 1394s 17s/step - loss: 0.7246 - acc: 0.9180 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 33/50\n",
      "80/80 [==============================] - 1399s 17s/step - loss: 0.6052 - acc: 0.9315 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 34/50\n",
      "80/80 [==============================] - 1399s 17s/step - loss: 0.7142 - acc: 0.9225 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 35/50\n",
      "80/80 [==============================] - 1407s 18s/step - loss: 0.6702 - acc: 0.9240 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 36/50\n",
      "80/80 [==============================] - 1393s 17s/step - loss: 0.6983 - acc: 0.9275 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 37/50\n",
      "80/80 [==============================] - 1393s 17s/step - loss: 0.6335 - acc: 0.9310 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 38/50\n",
      "80/80 [==============================] - 1394s 17s/step - loss: 0.6242 - acc: 0.9330 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 39/50\n",
      "80/80 [==============================] - 1397s 17s/step - loss: 0.6642 - acc: 0.9305 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 40/50\n",
      "80/80 [==============================] - 1395s 17s/step - loss: 0.5752 - acc: 0.9365 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 41/50\n",
      "80/80 [==============================] - 1391s 17s/step - loss: 0.5811 - acc: 0.9370 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 42/50\n",
      "80/80 [==============================] - 1381s 17s/step - loss: 0.7904 - acc: 0.9195 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 43/50\n",
      "80/80 [==============================] - 1407s 18s/step - loss: 0.6920 - acc: 0.9285 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 44/50\n",
      "80/80 [==============================] - 1671s 21s/step - loss: 0.5838 - acc: 0.9345 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 45/50\n",
      "80/80 [==============================] - 1513s 19s/step - loss: 0.5734 - acc: 0.9355 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 46/50\n",
      "80/80 [==============================] - 1495s 19s/step - loss: 0.7071 - acc: 0.9240 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 47/50\n",
      "80/80 [==============================] - 1603s 20s/step - loss: 0.5962 - acc: 0.9375 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 48/50\n",
      "80/80 [==============================] - 1508s 19s/step - loss: 0.5924 - acc: 0.9370 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 49/50\n",
      "80/80 [==============================] - 1501s 19s/step - loss: 0.5841 - acc: 0.9350 - val_loss: 1.0941 - val_acc: 0.9000\n",
      "Epoch 50/50\n",
      "80/80 [==============================] - 1465s 18s/step - loss: 0.5624 - acc: 0.9350 - val_loss: 1.0941 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f841c487748>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cat-dog-vgg16-fine-tune.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cat-dog-vgg16-fine-tune-model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
