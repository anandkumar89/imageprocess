{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random # parser function\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 100\n",
    "LOG_DIR = '.graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(filepath):\n",
    "    image_string = tf.read_file(filepath)\n",
    "    \n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize_images(image, [120, 120])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamp = 0.4\n",
    "cmin = 0.1\n",
    "cmax = 0.5\n",
    "hamp = 0.1 # 0-0.5\n",
    "smin = 0.1\n",
    "smax = 0.3\n",
    "transformations = [\\\n",
    "                   lambda x, y: (tf.image.random_flip_up_down(x), y),\\\n",
    "                   lambda x, y: (tf.image.random_flip_left_right(x), y),\\\n",
    "                   lambda x, y: (tf.image.transpose_image(x), y),\\\n",
    "                   lambda x, y: (tf.image.random_brightness(x, bamp), y),\\\n",
    "                   lambda x, y: (tf.image.random_contrast(x, cmin, cmax), y),\\\n",
    "                   lambda x, y: (tf.image.random_hue(x, hamp), y),\\\n",
    "                   lambda x, y: (tf.image.random_saturation(x, smin, smax), y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(filepath):\n",
    "    label = filepath.split('/')[1]\n",
    "    return 1 if label=='cat' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Transformation 0\n",
      "Finished Transformation 1\n",
      "Finished Transformation 2\n",
      "Finished Transformation 3\n",
      "Finished Transformation 4\n",
      "Finished Transformation 5\n",
      "Finished Transformation 6\n",
      "Cloned for number of epochs\n",
      "batching finished\n"
     ]
    }
   ],
   "source": [
    "# change how to split path for label if path is changed\n",
    "path = 'train_small/*/*.jpg'\n",
    "filepath = glob.glob(path)\n",
    "\n",
    "images = list(map(lambda x: parser(x), filepath))\n",
    "label  = list(map(lambda x: extract_label(x), filepath))\n",
    "\n",
    "# dataset = tf.data.Dataset.list_files(path, shuffle=True)\n",
    "# # dataset = tf.data.TFRecordDataset(files)\n",
    "# dataset = dataset.map(parser)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, label))\n",
    "dataset = dataset.shuffle(2000)\n",
    "for i in range(len(transformations)):\n",
    "    augment = dataset.map(transformations[i])\n",
    "    dataset.concatenate(augment)\n",
    "    print(\"Finished Transformation \" + str(i))\n",
    "dataset = dataset.map(lambda x, y: (tf.clip_by_value(x, 0.0, 1.0), y))\n",
    "dataset = dataset.repeat(NUM_EPOCHS)\n",
    "print(\"Cloned for number of epochs\")\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "print(\"batching finished\")\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     img = sess.run(features)\n",
    "#     label = sess.run(labels)\n",
    "#     batchlen = len(label)\n",
    "#     ncols = 5\n",
    "#     nrows = int(np.ceil(batchlen/ncols))\n",
    "#     fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "#     fig.set_figwidth(16)\n",
    "#     fig.set_figheight(nrows*3)\n",
    "#     for i in range(batchlen):\n",
    "#         a, b = i//ncols, i%ncols\n",
    "#         ax[a, b].imshow(img[i])\n",
    "#         ax[a, b].axis('off')\n",
    "#         ax[a, b].set_title(str(label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = True\n",
    "vgg = tf.layers.conv2d(inputs=features,filters=16, kernel_size=[3,3], padding='SAME', activation=tf.nn.relu)\n",
    "vgg = tf.layers.conv2d(inputs=vgg,filters=16, kernel_size=[3,3], padding='SAME', activation=tf.nn.relu)\n",
    "vgg = tf.layers.max_pooling2d(inputs=vgg, pool_size=[2,2], strides=2)\n",
    "\n",
    "vgg = tf.layers.flatten(vgg)\n",
    "\n",
    "vgg = tf.layers.dense(vgg, units=512, activation=tf.nn.relu)\n",
    "vgg = tf.layers.dropout(vgg, rate=0.5, training=is_training)\n",
    "\n",
    "# vgg = tf.layers.dense(vgg, units=100, activation=tf.nn.relu)\n",
    "# vgg = tf.layers.dropout(vgg, rate=0.5, training=is_training)\n",
    "\n",
    "logits = tf.layers.dense(vgg, units=1, activation=tf.nn.relu)\n",
    "\n",
    "predictions = {\n",
    "  \"classes\": tf.argmax(input=logits, axis=1),\n",
    "  \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "\n",
    "# Calculate Loss\n",
    "loss = tf.losses.softmax_cross_entropy(tf.reshape(labels, [-1,1]), logits)\n",
    "xent = tf.reduce_mean(loss)\n",
    "\n",
    "# Configure the Training \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train_step = optimizer.minimize(\n",
    "    loss=xent,\n",
    "    global_step=tf.train.get_global_step())\n",
    "\n",
    "# Add evaluation metrics\n",
    "eval_metric = {\n",
    "    \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "\n",
    "tf.summary.scalar('cross_entropy', xent, )\n",
    "tf.summary.scalar('accuracy', eval_metric[\"accuracy\"][0])\n",
    "summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, training accuracy : 0.00000\n",
      "Epoch:  1, training accuracy : 0.48000\n",
      "Epoch:  2, training accuracy : 0.46000\n",
      "Epoch:  3, training accuracy : 0.52000\n",
      "Epoch:  4, training accuracy : 0.51500\n",
      "Epoch:  5, training accuracy : 0.52800\n",
      "Epoch:  6, training accuracy : 0.51667\n",
      "Epoch:  7, training accuracy : 0.50286\n",
      "Epoch:  8, training accuracy : 0.49250\n",
      "Epoch:  9, training accuracy : 0.48444\n",
      "Epoch: 10, training accuracy : 0.47200\n",
      "Epoch: 11, training accuracy : 0.47818\n",
      "Epoch: 12, training accuracy : 0.48500\n",
      "Epoch: 13, training accuracy : 0.49231\n",
      "Epoch: 14, training accuracy : 0.49571\n",
      "Epoch: 15, training accuracy : 0.49067\n",
      "Epoch: 16, training accuracy : 0.49125\n",
      "Epoch: 17, training accuracy : 0.48824\n",
      "Epoch: 18, training accuracy : 0.48333\n",
      "Epoch: 19, training accuracy : 0.48316\n",
      "Epoch: 20, training accuracy : 0.48100\n",
      "Epoch: 21, training accuracy : 0.48000\n",
      "Epoch: 22, training accuracy : 0.47818\n",
      "Epoch: 23, training accuracy : 0.48000\n",
      "Epoch: 24, training accuracy : 0.48250\n",
      "Epoch: 25, training accuracy : 0.48000\n",
      "Epoch: 26, training accuracy : 0.47846\n",
      "Epoch: 27, training accuracy : 0.47852\n",
      "Epoch: 28, training accuracy : 0.47786\n",
      "Epoch: 29, training accuracy : 0.48000\n",
      "Epoch: 30, training accuracy : 0.48267\n",
      "Epoch: 31, training accuracy : 0.48581\n",
      "Epoch: 32, training accuracy : 0.48188\n",
      "Epoch: 33, training accuracy : 0.48121\n",
      "Epoch: 34, training accuracy : 0.48412\n",
      "Epoch: 35, training accuracy : 0.48229\n",
      "Epoch: 36, training accuracy : 0.48111\n",
      "Epoch: 37, training accuracy : 0.48595\n",
      "Epoch: 38, training accuracy : 0.48526\n",
      "Epoch: 39, training accuracy : 0.48513\n",
      "Epoch: 40, training accuracy : 0.48600\n",
      "Epoch: 41, training accuracy : 0.48780\n",
      "Epoch: 42, training accuracy : 0.48619\n",
      "Epoch: 43, training accuracy : 0.48884\n",
      "Epoch: 44, training accuracy : 0.49091\n",
      "Epoch: 45, training accuracy : 0.48978\n",
      "Epoch: 46, training accuracy : 0.48870\n",
      "Epoch: 47, training accuracy : 0.48809\n",
      "Epoch: 48, training accuracy : 0.48875\n",
      "Epoch: 49, training accuracy : 0.48735\n",
      "Epoch: 50, training accuracy : 0.48960\n",
      "Epoch: 51, training accuracy : 0.49020\n",
      "Epoch: 52, training accuracy : 0.49192\n",
      "Epoch: 53, training accuracy : 0.49132\n",
      "Epoch: 54, training accuracy : 0.49148\n",
      "Epoch: 55, training accuracy : 0.49309\n",
      "Epoch: 56, training accuracy : 0.49321\n",
      "Epoch: 57, training accuracy : 0.49298\n",
      "Epoch: 58, training accuracy : 0.49207\n",
      "Epoch: 59, training accuracy : 0.49254\n",
      "Epoch: 60, training accuracy : 0.49300\n",
      "Epoch: 61, training accuracy : 0.49344\n",
      "Epoch: 62, training accuracy : 0.49323\n",
      "Epoch: 63, training accuracy : 0.49270\n",
      "Epoch: 64, training accuracy : 0.49219\n",
      "Epoch: 65, training accuracy : 0.49446\n",
      "Epoch: 66, training accuracy : 0.49545\n",
      "Epoch: 67, training accuracy : 0.49433\n",
      "Epoch: 68, training accuracy : 0.49382\n",
      "Epoch: 69, training accuracy : 0.49507\n",
      "Epoch: 70, training accuracy : 0.49600\n",
      "Epoch: 71, training accuracy : 0.49634\n",
      "Epoch: 72, training accuracy : 0.49694\n",
      "Epoch: 73, training accuracy : 0.49836\n",
      "Epoch: 74, training accuracy : 0.49730\n",
      "Epoch: 75, training accuracy : 0.49733\n",
      "Epoch: 76, training accuracy : 0.49763\n",
      "Epoch: 77, training accuracy : 0.49792\n",
      "Epoch: 78, training accuracy : 0.49718\n",
      "Epoch: 79, training accuracy : 0.49848\n",
      "Epoch: 80, training accuracy : 0.49775\n",
      "Epoch: 81, training accuracy : 0.49704\n",
      "Epoch: 82, training accuracy : 0.49683\n",
      "Epoch: 83, training accuracy : 0.49614\n",
      "Epoch: 84, training accuracy : 0.49762\n",
      "Epoch: 85, training accuracy : 0.49765\n",
      "Epoch: 86, training accuracy : 0.49674\n",
      "Epoch: 87, training accuracy : 0.49701\n",
      "Epoch: 88, training accuracy : 0.49818\n",
      "Epoch: 89, training accuracy : 0.49730\n",
      "Epoch: 90, training accuracy : 0.49756\n",
      "Epoch: 91, training accuracy : 0.49736\n",
      "Epoch: 92, training accuracy : 0.49674\n",
      "Epoch: 93, training accuracy : 0.49677\n",
      "Epoch: 94, training accuracy : 0.49574\n",
      "Epoch: 95, training accuracy : 0.49621\n",
      "Epoch: 96, training accuracy : 0.49625\n",
      "Epoch: 97, training accuracy : 0.49588\n",
      "Epoch: 98, training accuracy : 0.49551\n",
      "Epoch: 99, training accuracy : 0.49455\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with tf.Session() as sess:\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    saver  = tf.train.Saver()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "            [train_accuracy, s] = sess.run([eval_metric[\"accuracy\"], summ])\n",
    "            writer.add_summary(s, counter)\n",
    "            print(\"Epoch: %2d, training accuracy : %6.5f\"%(epoch, train_accuracy[0]))\n",
    "            sess.run(train_step)\n",
    "            counter = counter+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
