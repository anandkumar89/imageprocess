{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random # parser function\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 100\n",
    "LOG_DIR = '.graph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(filepath):\n",
    "    image_string = tf.read_file(filepath)\n",
    "    \n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    image = tf.image.resize_images(image, [120, 120])\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bamp = 0.4\n",
    "cmin = 0.1\n",
    "cmax = 0.5\n",
    "hamp = 0.1 # 0-0.5\n",
    "smin = 0.1\n",
    "smax = 0.3\n",
    "transformations = [\\\n",
    "                   lambda x, y: (tf.image.random_flip_up_down(x), y),\\\n",
    "                   lambda x, y: (tf.image.random_flip_left_right(x), y),\\\n",
    "                   lambda x, y: (tf.image.transpose_image(x), y),\\\n",
    "                   lambda x, y: (tf.image.random_brightness(x, bamp), y),\\\n",
    "                   lambda x, y: (tf.image.random_contrast(x, cmin, cmax), y),\\\n",
    "                   lambda x, y: (tf.image.random_hue(x, hamp), y),\\\n",
    "                   lambda x, y: (tf.image.random_saturation(x, smin, smax), y)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label(filepath):\n",
    "    label = filepath.split('/')[1]\n",
    "    return 1 if label=='cat' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change how to split path for label if path is changed\n",
    "path = 'train_small/*/*.jpg'\n",
    "filepath = glob.glob(path)\n",
    "\n",
    "images = list(map(lambda x: parser(x), filepath))\n",
    "label  = list(map(lambda x: extract_label(x), filepath))\n",
    "\n",
    "# dataset = tf.data.Dataset.list_files(path, shuffle=True)\n",
    "# # dataset = tf.data.TFRecordDataset(files)\n",
    "# dataset = dataset.map(parser)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((images, label))\n",
    "dataset = dataset.shuffle(2000)\n",
    "for i in range(len(transformations)):\n",
    "    augment = dataset.map(transformations[i])\n",
    "    dataset.concatenate(augment)\n",
    "    print(\"Finished Transformation \" + str(i))\n",
    "dataset = dataset.map(lambda x, y: (tf.clip_by_value(x, 0.0, 1.0), y))\n",
    "dataset = dataset.repeat(NUM_EPOCHS)\n",
    "print(\"Cloned for number of epochs\")\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "print(\"batching finished\")\n",
    "dataset = dataset.prefetch(1)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "features, labels = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     img = sess.run(features)\n",
    "#     label = sess.run(labels)\n",
    "#     batchlen = len(label)\n",
    "#     ncols = 5\n",
    "#     nrows = int(np.ceil(batchlen/ncols))\n",
    "#     fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "#     fig.set_figwidth(16)\n",
    "#     fig.set_figheight(nrows*3)\n",
    "#     for i in range(batchlen):\n",
    "#         a, b = i//ncols, i%ncols\n",
    "#         ax[a, b].imshow(img[i])\n",
    "#         ax[a, b].axis('off')\n",
    "#         ax[a, b].set_title(str(label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training = True\n",
    "vgg = tf.layers.conv2d(inputs=features,filters=16, kernel_size=[3,3], padding='SAME', activation=tf.nn.relu)\n",
    "vgg = tf.layers.conv2d(inputs=vgg,filters=16, kernel_size=[3,3], padding='SAME', activation=tf.nn.relu)\n",
    "vgg = tf.layers.max_pooling2d(inputs=vgg, pool_size=[2,2], strides=2)\n",
    "\n",
    "vgg = tf.layers.flatten(vgg)\n",
    "\n",
    "vgg = tf.layers.dense(vgg, units=512, activation=tf.nn.relu)\n",
    "vgg = tf.layers.dropout(vgg, rate=0.5, training=is_training)\n",
    "\n",
    "# vgg = tf.layers.dense(vgg, units=100, activation=tf.nn.relu)\n",
    "# vgg = tf.layers.dropout(vgg, rate=0.5, training=is_training)\n",
    "\n",
    "logits = tf.layers.dense(vgg, units=1, activation=tf.nn.relu)\n",
    "\n",
    "predictions = {\n",
    "  \"classes\": tf.argmax(input=logits, axis=1),\n",
    "  \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "\n",
    "# Calculate Loss\n",
    "loss = tf.losses.softmax_cross_entropy(tf.reshape(labels, [-1,1]), logits)\n",
    "xent = tf.reduce_mean(loss)\n",
    "\n",
    "# Configure the Training \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train_step = optimizer.minimize(\n",
    "    loss=xent,\n",
    "    global_step=tf.train.get_global_step())\n",
    "\n",
    "# Add evaluation metrics\n",
    "eval_metric = {\n",
    "    \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "\n",
    "tf.summary.scalar('cross_entropy', xent, )\n",
    "tf.summary.scalar('accuracy', eval_metric[\"accuracy\"][0])\n",
    "summ = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "with tf.Session() as sess:\n",
    "    init_g = tf.global_variables_initializer()\n",
    "    init_l = tf.local_variables_initializer()\n",
    "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    saver  = tf.train.Saver()\n",
    "    sess.run(init_g)\n",
    "    sess.run(init_l)\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "            [train_accuracy, s] = sess.run([eval_metric[\"accuracy\"], summ])\n",
    "            writer.add_summary(s, counter)\n",
    "            print(\"Epoch: %2d, training accuracy : %6.5f\"%(epoch, train_accuracy[0]))\n",
    "            sess.run(train_step)\n",
    "            counter = counter+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
